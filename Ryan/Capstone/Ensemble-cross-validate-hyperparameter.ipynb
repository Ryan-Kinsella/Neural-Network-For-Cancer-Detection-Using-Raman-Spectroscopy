{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pd.options.display.max_rows = 8\n",
    "pd.options.display.max_columns = 9\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "dataset = pd.read_csv(\"Dataset_Github_Labeled.csv\")\n",
    "#addNoise(dataset, 1) #second number for 2^power size i.e. 1->2 times, 2-> 4 times, 3->8 times, takes a while\n",
    "x= dataset.drop(['class'], axis=1)\n",
    "y= dataset['class']\n",
    "for i in range (0,dataset.shape[0]):\n",
    "    if y[i].startswith('High-grade'):\n",
    "        y[i] = 'High-grade'\n",
    "    elif y[i].startswith('Low-grade'):\n",
    "        y[i] = 'Low-grade'\n",
    "    elif y[i].startswith('Normal'):\n",
    "        y[i] = 'Normal'\n",
    "\n",
    "def addNoise(data,powerIN):\n",
    "    sd = dataset.std(axis=0)\n",
    "    m = dataset.mean(axis = 0)\n",
    "    original = (data.shape[0])\n",
    "    datacopy = data.copy()\n",
    "    frames = [data,datacopy]\n",
    "    for i in range(powerIN): #how many duplicates\n",
    "        data2 = pd.concat(frames,ignore_index=True)\n",
    "    for i in range(original, data.shape[0]):\n",
    "        for j in range (1,1365):\n",
    "            data.iloc[i,j]+=(np.random.normal(m[j], sd[j], 1))[0]\n",
    "    return data\n",
    "\n",
    "def splitData(dataset):\n",
    "    training, validation, test = np.split(dataset.sample(frac=1), [int(.6*len(dataset)), int(.8*len(dataset))]) \n",
    "    x_train = training.drop(['class'], axis=1)\n",
    "    y_train = training['class']\n",
    "    x_validation=validation.drop(['class'], axis=1)\n",
    "    y_validation=validation['class']\n",
    "    x_test=test.drop(['class'], axis=1)\n",
    "    y_test=test['class']\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    y_train= lbl_encoder.fit_transform(y_train)\n",
    "    y_test= lbl_encoder.fit_transform(y_test)\n",
    "    y_validation= lbl_encoder.fit_transform(y_validation)\n",
    "    return x_train, y_train, x_validation, y_validation, x_test, y_test\n",
    "\n",
    "# Convert numeric features into Dense Tensors, and construct the feature columns\n",
    "def construct_feature_columns(input_features_DataFrame):\n",
    "  tensorSet = ([])\n",
    "  for elem in input_features_DataFrame:\n",
    "    tensorSet.append( tf.feature_column.numeric_column(str(elem)) )\n",
    "  return tensorSet\n",
    "\n",
    "# Create the input function for training + evaluation. boolean = True for training.\n",
    "def input_fn(features, labels, training=True, batch_size=32 ):\n",
    "    dataf = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    if training:\n",
    "        dataf = dataf.shuffle(200).repeat()\n",
    "    return dataf.batch(batch_size=batch_size)\n",
    "\n",
    "def trainModels(feature_columns, x_train, y_train,x_test,y_test):\n",
    "    modelCNN,accuracy,predictions = trainCNN(x_train,y_train,x_test, y_test)\n",
    "    modelSVM = trainSVM(x_train, y_train)\n",
    "    modelDNN = trainDNN(feature_columns, x_train, y_train)\n",
    "    modelTREE = trainTree(feature_columns, x_train, y_train)\n",
    "    return modelSVM, modelDNN, modelTREE, modelCNN, accuracy,predictions\n",
    "\n",
    "def trainTree(feature_columns, x_train, y_train):\n",
    "    treeclassifier = tree.DecisionTreeClassifier()\n",
    "    treeclassifier = treeclassifier.fit(x_train, y_train)\n",
    "\n",
    "    return treeclassifier\n",
    "\n",
    "def trainCNN(trainX, trainY, testX, testY):\n",
    "    trainY = keras.utils.to_categorical(trainY)\n",
    "    testY = keras.utils.to_categorical(testY)\n",
    "\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    trainX = np.expand_dims(trainX, axis=2)\n",
    "    testX = np.expand_dims(testX, axis=2)\n",
    "\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainY.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    _, accuracy = model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "    OP = model.predict_proba(testX)\n",
    "\n",
    "    return model, accuracy, OP\n",
    "\n",
    "def trainDNN(feature_columns, x_train, y_train):\n",
    "    learning_rate=0.001\n",
    "    if (tf.__version__[0] == '2'):\n",
    "        optimizer_adam= tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer_adam= tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    hidden_units=[37,30,19]\n",
    "    model=tf.estimator.DNNClassifier(hidden_units=hidden_units, feature_columns=feature_columns,  optimizer=optimizer_adam, n_classes=3)\n",
    "    model.train(input_fn=lambda: input_fn(features=x_train, labels=y_train, training=True), steps=1000) # originally steps=1000 from template\n",
    "    return model\n",
    "\n",
    "def trainSVM(x_train, y_train):\n",
    "    model = SVC(kernel='linear', probability = True)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def getAccuracy(x_test, y_test, modelSVM, modelDNN, modelTREE, accuracyCNN):\n",
    "    pSVM = modelSVM.predict(x_test)\n",
    "    accuracySVM = accuracy_score(pSVM,y_test)\n",
    "    pTREE = modelTREE.predict(x_test)\n",
    "    accuracyTREE = accuracy_score(pTREE, y_test)\n",
    "    pDNN = modelDNN.evaluate(input_fn=lambda: input_fn(features=x_test, labels=y_test, training=False), steps=1)\n",
    "    accuracyDNN = pDNN[\"accuracy\"]\n",
    "\n",
    "    return accuracySVM, accuracyDNN, accuracyTREE, accuracyCNN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmpsptn3_0h\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\R-k-l\\\\AppData\\\\Local\\\\Temp\\\\tmpsptn3_0h', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000275AF4BBAC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From c:\\users\\r-k-l\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\r-k-l\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmpsptn3_0h\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.102807, step = 0\n",
      "INFO:tensorflow:global_step/sec: 16.8116\n",
      "INFO:tensorflow:loss = 0.5022146, step = 100 (5.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4231\n",
      "INFO:tensorflow:loss = 0.25878015, step = 200 (2.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1987\n",
      "INFO:tensorflow:loss = 0.091459155, step = 300 (2.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5842\n",
      "INFO:tensorflow:loss = 0.07962422, step = 400 (2.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2267\n",
      "INFO:tensorflow:loss = 0.032975588, step = 500 (2.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5989\n",
      "INFO:tensorflow:loss = 0.012679851, step = 600 (2.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7689\n",
      "INFO:tensorflow:loss = 0.0071600443, step = 700 (2.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8135\n",
      "INFO:tensorflow:loss = 0.0030314415, step = 800 (2.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7533\n",
      "INFO:tensorflow:loss = 0.004896006, step = 900 (2.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmpsptn3_0h\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.002274764.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmpsptn3_0h\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-06T17:47:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmpsptn3_0h\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-06-17:47:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9375, average_loss = 0.12114235, global_step = 1000, loss = 0.12114235\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmpsptn3_0h\\model.ckpt-1000\n",
      "[1 1 0 0 0 0 1 2 0 1 2 0 2 0 0 0 1 1 0 0 0 0 2 1 2 0 1 0 0 1 1 1 0 1 0 2 1\n",
      " 2 1 0 0 2 0 1 1 0 0 0 0 2 0 0 0 0 1 2 0 0 0 2 2 2 2 1 2 1 1 0 0 0 0 0 1 1\n",
      " 1 0 1 1 1 0 1 0 0 0 0 1 2 0 1 2 0 0 0 1 2 2 2 0 0 1 0 0 1 1 2 2 2 2 0 1 2\n",
      " 1 2 1 1 0 0 0 1 1 1 1 2 2 2 1 1 0 1 0 0 0 2 2 1 2 1 0 1 1 0 0 0 1 2 0 2 0\n",
      " 1 0 0 0 1 0 2 0 0 2 2 2 2 0 2 1 2 0 0 1 0 0 1 2 2 2 2 1 1 2 1 2 1 0 1 0 1\n",
      " 1 1 2 1 2 1 2 1 2]\n",
      "DNN: 0.9375\n",
      "CNN: 0.7384615540504456\n",
      "SVM: 0.8615384615384616\n",
      "TREE:  0.7692307692307693\n",
      "...................\n",
      "ENS: 0.8923076923076924\n",
      "[[28  0  1]\n",
      " [ 0 17  4]\n",
      " [ 2  0 13]]\n"
     ]
    }
   ],
   "source": [
    "#split into train/test/val\n",
    "x_train, y_train, x_validation, y_validation, x_test, y_test = splitData(dataset)\n",
    "#construct feature columns\n",
    "x_labels = x.head(0)\n",
    "feature_columns=construct_feature_columns(x_labels)\n",
    "\n",
    "modelSVM, modelDNN, modelTREE, modelCNN, accuracyCNN, predictionsCNN = trainModels(feature_columns, x_train, y_train,x_test,y_test)\n",
    "ptemp = list(modelDNN.predict(input_fn=lambda: input_fn(features=x_test, labels=y_test, training=False)))\n",
    "predictionsDNN = []\n",
    "for i in range(len(ptemp)):\n",
    "    predictionsDNN.append(ptemp[i][\"probabilities\"])\n",
    "predictionsSVM = modelSVM.predict_proba(x_test) \n",
    "predictionsTREE = modelTREE.predict_proba(x_test)\n",
    "\n",
    "accuracySVM, accuracyDNN, accuracyTREE, accuracyCNN = getAccuracy(x_test, y_test, modelSVM, modelDNN, modelTREE, accuracyCNN)\n",
    "\n",
    "print(y_train)\n",
    "predictionsENS = []\n",
    "\n",
    "for i in range(len(predictionsDNN)):\n",
    "    tempDNN = predictionsDNN[i]\n",
    "    tempCNN = predictionsCNN[i]\n",
    "    tempTREE = predictionsTREE[i]\n",
    "    tempSVM = predictionsSVM[i]\n",
    "    score0 = accuracyDNN*tempDNN[0] + accuracyCNN*tempCNN[0] + accuracyTREE*accuracyTREE*tempTREE[0] + accuracySVM*tempSVM[0]\n",
    "    score1 = accuracyDNN*tempDNN[1] + accuracyCNN*tempCNN[1] + accuracyTREE*accuracyTREE*tempTREE[1] + accuracySVM*tempSVM[1]\n",
    "    score2 = accuracyDNN*tempDNN[2] + accuracyCNN*tempCNN[2] + accuracyTREE*accuracyTREE*tempTREE[2] + accuracySVM*tempSVM[2]\n",
    "    if score0 > score1 and score0 > score2:\n",
    "        predictionsENS.append(0)\n",
    "    elif score1 > score0 and score1 > score2:\n",
    "        predictionsENS.append(1)\n",
    "    elif score2 > score0 and score2 > score1:\n",
    "        predictionsENS.append(2)\n",
    "\n",
    "\n",
    "finalAccuracy = accuracy_score(predictionsENS, y_test)\n",
    "print('DNN:' , accuracyDNN)\n",
    "print('CNN:', accuracyCNN)\n",
    "print('SVM:', accuracySVM)\n",
    "print('TREE: ', accuracyTREE)\n",
    "print('...................')\n",
    "print('ENS:' ,finalAccuracy)\n",
    "print(confusion_matrix(predictionsENS, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "def cross_validation_svm(hyperparameters, X, y, num_folds=5):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model-sklearn untrained model to be cross validated. \n",
    "        X-DataFrame without labels\n",
    "        y-labels for same size DataFrame as X\n",
    "        num_folds-number of folds to split for cross validation. \n",
    "\n",
    "    Returns:\n",
    "        sklearn model, best fold for model_untrained. \n",
    "    \"\"\"\n",
    "    # Perform Cross Validation. \n",
    "    cv = StratifiedKFold(n_splits=num_folds)\n",
    "    i=1\n",
    "    best_accuracy=0\n",
    "    best_model_test_index=[]\n",
    "    for train_index, test_index, in cv.split(X, y):\n",
    "        # Select the indices. \n",
    "        sm = SMOTE()\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "        \n",
    "        model = SVC(kernel=hyperparameters[0], probability=hyperparameters[1])\n",
    "        model.fit(X_train_oversampled, y_train_oversampled ) \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score= model.predict_proba(X_test)[:,1]\n",
    "\n",
    "        # Compute results.\n",
    "        accuracy=model.score(X_test, y_test)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy=accuracy\n",
    "            best_model=model\n",
    "            best_model_test_index = test_index\n",
    "#         f1=f1_score(y_test, y_pred, average=\"macro\")\n",
    "#         recall=recall_score(y_test, y_pred, average=\"macro\")\n",
    "#         precision=precision_score(y_test, y_pred, average=\"macro\")\n",
    "#         auc=roc_auc_score(y_test, y_score)\n",
    "#         average_precision=average_precision_score(y_test, y_score)\n",
    "\n",
    "        # Show results. \n",
    "        print('__________________________________________________________')\n",
    "        print('For fold:', i)\n",
    "        print('Accuracy: {0:0.4f}'.format(accuracy))\n",
    "#         print(\"f1 score: {0:0.4f}\".format(f1))\n",
    "#         print(\"recall score: {0:0.4f}\".format(recall))\n",
    "#         print(\"precision score: {0:0.4f}\".format(precision))\n",
    "#         print('AUC score: {0:0.4f}'.format(auc))\n",
    "#         disp = plot_precision_recall_curve(model, X_test, y_test)\n",
    "#         disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "#                        'Average Percision={0:0.2f}'.format(average_precision))\n",
    "        i+=1\n",
    "    return best_model, best_model_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________\n",
      "For fold: 1\n",
      "Accuracy: 0.7846\n",
      "__________________________________________________________\n",
      "For fold: 2\n",
      "Accuracy: 0.8615\n",
      "__________________________________________________________\n",
      "For fold: 3\n",
      "Accuracy: 0.6615\n",
      "__________________________________________________________\n",
      "For fold: 4\n",
      "Accuracy: 0.7846\n",
      "__________________________________________________________\n",
      "For fold: 5\n",
      "Accuracy: 0.7969\n"
     ]
    }
   ],
   "source": [
    "# model = SVC(kernel='linear', probability = True)\n",
    "hyperparam = ['linear', True]\n",
    "best_model, abc = cross_validation_svm(hyperparam, x, y, num_folds=5)\n",
    "# best_model.score(x.iloc[ind], y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615384615384616"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(x.iloc[abc], y[abc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 367.45 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.759 (std: 0.067)\n",
      "Parameters: {'max_depth ': 3, 'learning_rate': 0.15}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.759 (std: 0.067)\n",
      "Parameters: {'max_depth ': 4, 'learning_rate': 0.15}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.759 (std: 0.074)\n",
      "Parameters: {'max_depth ': 2, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.759 (std: 0.074)\n",
      "Parameters: {'max_depth ': 4, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.759 (std: 0.074)\n",
      "Parameters: {'max_depth ': 3, 'learning_rate': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code block will create n_iter_search models, and order them by accuracy based on hyperparameter values. \n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# XGBoost\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "model=xgb.XGBClassifier()\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'learning_rate' : [0.05, 0.1, 0.15, 0.2],\n",
    "              'max_depth ' : [2,3,4]\n",
    "             }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(x, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
