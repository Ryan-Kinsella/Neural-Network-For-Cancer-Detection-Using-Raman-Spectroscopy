{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.options.display.max_rows = 8\n",
    "pd.options.display.max_columns = 9\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "dataset = pd.read_csv(\"Dataset_Github_Labeled.csv\")\n",
    "#addNoise(dataset, 1) #second number for 2^power size i.e. 1->2 times, 2-> 4 times, 3->8 times, takes a while\n",
    "x= dataset.drop(['class'], axis=1)\n",
    "y= dataset['class']\n",
    "for i in range (0,dataset.shape[0]):\n",
    "    if y[i].startswith('High-grade'):\n",
    "        y[i] = 'High-grade'\n",
    "    elif y[i].startswith('Low-grade'):\n",
    "        y[i] = 'Low-grade'\n",
    "    elif y[i].startswith('Normal'):\n",
    "        y[i] = 'Normal'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(data,powerIN):\n",
    "    sd = dataset.std(axis=0)\n",
    "    m = dataset.mean(axis = 0)\n",
    "    original = (data.shape[0])\n",
    "    datacopy = data.copy()\n",
    "    frames = [data,datacopy]\n",
    "    for i in range(powerIN): #how many duplicates\n",
    "        data2 = pd.concat(frames,ignore_index=True)\n",
    "    for i in range(original, data.shape[0]):\n",
    "        print(i)\n",
    "        for j in range (1,1365):\n",
    "            data.iloc[i,j]+=(np.random.normal(m[j], sd[j], 1))[0]\n",
    "    return data\n",
    "\n",
    "def splitData(dataset):\n",
    "    training, validation, test = np.split(dataset.sample(frac=1), [int(.6*len(dataset)), int(.8*len(dataset))]) \n",
    "    x_train = training.drop(['class'], axis=1)\n",
    "    y_train = training['class']\n",
    "    x_validation=validation.drop(['class'], axis=1)\n",
    "    y_validation=validation['class']\n",
    "    x_test=test.drop(['class'], axis=1)\n",
    "    y_test=test['class']\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    y_train= lbl_encoder.fit_transform(y_train)\n",
    "    y_test= lbl_encoder.fit_transform(y_test)\n",
    "    y_validation= lbl_encoder.fit_transform(y_validation)\n",
    "    return x_train, y_train, x_validation, y_validation, x_test, y_test\n",
    "\n",
    "# Convert numeric features into Dense Tensors, and construct the feature columns\n",
    "def construct_feature_columns(input_features_DataFrame):\n",
    "    tensorSet = ([])\n",
    "    for elem in input_features_DataFrame:\n",
    "        tensorSet.append( tf.feature_column.numeric_column(str(elem)) )\n",
    "    return tensorSet\n",
    "\n",
    "# Create the input function for training + evaluation. boolean = True for training.\n",
    "def input_fn(features, labels, training=True, batch_size=32 ):\n",
    "    dataf = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    if training:\n",
    "        dataf = dataf.shuffle(200).repeat()\n",
    "    return dataf.batch(batch_size=batch_size)\n",
    "\n",
    "def trainModels(feature_columns, x_train, y_train,x_test,y_test):\n",
    "    modelCNN,accuracy,predictions = trainCNN(x_train,y_train,x_test, y_test)\n",
    "    print('STARTING TO TRAIN THE MODELS--------------------------------------------------')\n",
    "    modelSVM = trainSVM(x_train, y_train)\n",
    "    print('FINISHED THE SVM--------------------------------------------------------------')\n",
    "    modelDNN = trainDNN(feature_columns, x_train, y_train)\n",
    "    print('FINISHED THE DNN--------------------------------------------------------------')\n",
    "    modelTREE = trainTree(feature_columns, x_train, y_train)\n",
    "    print('FINISHED THE TREE-------------------------------------------------------------')\n",
    "\n",
    "    return modelSVM, modelDNN, modelTREE, modelCNN, accuracy,predictions\n",
    "\n",
    "def trainTree(feature_columns, x_train, y_train):\n",
    "    treeclassifier = tree.DecisionTreeClassifier()\n",
    "    treeclassifier = treeclassifier.fit(x_train, y_train)\n",
    "\n",
    "    return treeclassifier\n",
    "\n",
    "def trainCNN(trainX, trainY, testX, testY):\n",
    "    trainY = keras.utils.to_categorical(trainY)\n",
    "    testY = keras.utils.to_categorical(testY)\n",
    "\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    trainX = np.expand_dims(trainX, axis=2)\n",
    "    testX = np.expand_dims(testX, axis=2)\n",
    "\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainY.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    _, accuracy = model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "    OP = model.predict_proba(testX)\n",
    "\n",
    "    return model, accuracy, OP\n",
    "\n",
    "def trainDNN(feature_columns, x_train, y_train):\n",
    "    learning_rate=0.001\n",
    "    if (tf.__version__[0] == '2'):\n",
    "        optimizer_adam= tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer_adam= tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    hidden_units=[37,30,19]\n",
    "    model=tf.estimator.DNNClassifier(hidden_units=hidden_units, feature_columns=feature_columns,  optimizer=optimizer_adam, n_classes=3)\n",
    "    model.train(input_fn=lambda: input_fn(features=x_train, labels=y_train, training=True), steps=1000) # originally steps=1000 from template\n",
    "    return model\n",
    "\n",
    "def trainSVM(x_train, y_train):\n",
    "    model = SVC(kernel='linear', probability = True)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TO TRAIN THE MODELS--------------------------------------------------\n",
      "FINISHED THE SVM--------------------------------------------------------------\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmps71b0q47\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\R-k-l\\\\AppData\\\\Local\\\\Temp\\\\tmps71b0q47', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023680A21B00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From c:\\users\\r-k-l\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\r-k-l\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmps71b0q47\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0994511, step = 0\n",
      "INFO:tensorflow:global_step/sec: 14.3245\n",
      "INFO:tensorflow:loss = 0.34767473, step = 100 (6.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.6651\n",
      "INFO:tensorflow:loss = 0.13239601, step = 200 (2.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1626\n",
      "INFO:tensorflow:loss = 0.08712815, step = 300 (2.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2974\n",
      "INFO:tensorflow:loss = 0.023750406, step = 400 (2.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4206\n",
      "INFO:tensorflow:loss = 0.007485804, step = 500 (2.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9831\n",
      "INFO:tensorflow:loss = 0.0070787547, step = 600 (2.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.4506\n",
      "INFO:tensorflow:loss = 0.005701714, step = 700 (2.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.1355\n",
      "INFO:tensorflow:loss = 0.0023272969, step = 800 (2.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.2094\n",
      "INFO:tensorflow:loss = 0.0019707629, step = 900 (2.368 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmps71b0q47\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0014799689.\n",
      "FINISHED THE DNN--------------------------------------------------------------\n",
      "FINISHED THE TREE-------------------------------------------------------------\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\R-k-l\\AppData\\Local\\Temp\\tmps71b0q47\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "DNN: [6.0272293e-07 9.6930861e-01 3.0690774e-02]\n",
      "TREE: [0. 0. 1.]\n",
      "SVM: [0.01953685 0.54357247 0.43689068]\n",
      "CNN:  [0.00598297 0.91800624 0.07601073]\n"
     ]
    }
   ],
   "source": [
    "#split into train/test/val\n",
    "x_train, y_train, x_validation, y_validation, x_test, y_test = splitData(dataset)\n",
    "#construct feature columns\n",
    "x_labels = x.head(0)\n",
    "feature_columns=construct_feature_columns(x_labels)\n",
    "\n",
    "modelSVM, modelDNN, modelTREE, modelCNN, accuracy, predictionsCNN = trainModels(feature_columns, x_train, y_train,x_test,y_test)\n",
    "ptemp = list(modelDNN.predict(input_fn=lambda: input_fn(features=x_test, labels=y_test, training=False)))\n",
    "predictionsDNN = []\n",
    "for i in range(len(ptemp)):\n",
    "    predictionsDNN.append(ptemp[i][\"probabilities\"])\n",
    "predictionsSVM = modelSVM.predict_proba(x_test) \n",
    "predictionsTREE = modelTREE.predict_proba(x_test)\n",
    "\n",
    "\n",
    "print ('DNN:' ,predictionsDNN[0])\n",
    "print ('TREE:', predictionsTREE[0])\n",
    "print ('SVM:' ,predictionsSVM[0])\n",
    "print ('CNN: ',predictionsCNN[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesnt work yet\n",
    "def cross_validation_sklearn(trained_model, num_folds, X, y):\n",
    "    i=1\n",
    "    cv = StratifiedKFold(n_splits=num_folds)\n",
    "    total_accuracy=0\n",
    "    total_f1=0\n",
    "    total_precision=0\n",
    "    total_recall=0\n",
    "    total_auc=0\n",
    "    for train_index, test_index, in cv.split(X, y):\n",
    "        sm = SMOTE()\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "        model.fit(X_train_oversampled, y_train_oversampled) \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score= model.predict_proba(X_test)[:,1]\n",
    "\n",
    "        # Compute results.\n",
    "        accuracy=model.score(X_test, y_test)\n",
    "        f1=f1_score(y_test, y_pred, average=\"macro\")\n",
    "        recall=recall_score(y_test, y_pred, average=\"macro\")\n",
    "        precision=precision_score(y_test, y_pred, average=\"macro\")\n",
    "        auc=roc_auc_score(y_test, y_score)\n",
    "        average_precision=average_precision_score(y_test, y_score)\n",
    "\n",
    "        # Show results. \n",
    "        print('__________________________________________________________')\n",
    "        print('For fold:', i)\n",
    "        print('Accuracy: {0:0.4f}'.format(accuracy))\n",
    "        print(\"f1 score: {0:0.4f}\".format(f1))\n",
    "        print(\"recall score: {0:0.4f}\".format(recall))\n",
    "        print(\"precision score: {0:0.4f}\".format(precision))\n",
    "        print('AUC score: {0:0.4f}'.format(auc))\n",
    "        disp = plot_precision_recall_curve(model, X_test, y_test)\n",
    "        disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                       'Average Precision={0:0.2f}'.format(average_precision))\n",
    "\n",
    "        # Update logic for filling in average values for table. \n",
    "        total_accuracy+=accuracy\n",
    "        total_f1+=f1\n",
    "        total_recall+=recall\n",
    "        total_precision+=precision\n",
    "        total_auc+=auc\n",
    "        i+=1\n",
    "\n",
    "\n",
    "    print(\"total_accuracy:\", round(total_accuracy/number_splits, 4))\n",
    "    print(\"total_f1:\", round(total_f1/number_splits, 4))\n",
    "    print(\"total_recall:\", round(total_recall/number_splits, 4))\n",
    "    print(\"total_precision:\", round(total_precision/number_splits, 4))\n",
    "    print(\"total_auc:\", round(total_auc/number_splits, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_prediction(predictionsDNN): # used for confusion matrix\n",
    "    predictionsDNN=list(predictionsDNN)\n",
    "    aList=[]\n",
    "    for elem in predictionsDNN:\n",
    "        aList.append(np.argmax(elem))\n",
    "    return aList\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN: \n",
      "tf.Tensor(\n",
      "[[24  0  0]\n",
      " [ 0 19  2]\n",
      " [ 4  1 15]], shape=(3, 3), dtype=int32)\n",
      "CNN: \n",
      "tf.Tensor(\n",
      "[[24  0  0]\n",
      " [ 0 21  0]\n",
      " [ 8  3  9]], shape=(3, 3), dtype=int32)\n",
      "SVM:\n",
      "[[24  0  0]\n",
      " [ 0 17  4]\n",
      " [ 3  0 17]]\n",
      "Tree:\n",
      "[[22  0  2]\n",
      " [ 2 14  5]\n",
      " [ 5  5 10]]\n"
     ]
    }
   ],
   "source": [
    "if (tf.__version__[0] == '2'):\n",
    "    confusion_matrix_DNN = tf.math.confusion_matrix(labels=list(y_test), \n",
    "            predictions=max_prediction(predictionsDNN), num_classes=3)\n",
    "    confusion_matrix_CNN = tf.math.confusion_matrix(labels=list(y_test), \n",
    "            predictions=max_prediction(predictionsCNN), num_classes=3)    \n",
    "else:\n",
    "    confusion_matrix_DNN = tf.confusion_matrix(labels=list(y_test), \n",
    "            predictions=max_prediction(predictionsDNN), num_classes=3)\n",
    "    confusion_matrix_CNN = tf.confusion_matrix(labels=list(y_test), \n",
    "            predictions=max_prediction(predictionsCNN), num_classes=3) \n",
    "print(\"DNN: \")\n",
    "print(confusion_matrix_DNN)\n",
    "print(\"CNN: \")\n",
    "print(confusion_matrix_CNN)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"SVM:\")\n",
    "print(confusion_matrix(y_test, max_prediction(predictionsSVM)))\n",
    "print(\"Tree:\")\n",
    "print(confusion_matrix(y_test, max_prediction(predictionsTREE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_prediction_in_tf(predictionsSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
