{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter methods are generally used as a preprocessing step. The selection of\n",
    "attributes/features is independent of any machine learning algorithms. Instead, \n",
    "attributes are selected on the basis of their scores in various statistical \n",
    "tests for their correlation with the outcome variable. \n",
    "\n",
    "Wrapper/Embedded methods for attribute selection were considered but could \n",
    "not be utilized due to runtime. Multiple models are created and tested with\n",
    "each pass increasing as the number of attributes increases, therefore would\n",
    "only be viable for datasets of around ~20 attributes. \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "df = pd.read_csv(\"Dataset_Github_Labeled.csv\")\n",
    "x=df.drop(['class'], axis=1)\n",
    "# print(x.tail())\n",
    "y=df['class']\n",
    "\n",
    "# change y in the csv file to be assigned to one of three classes: High-grade, Low-grade, Normal\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "for i in range (0,324): # 0 - 323, same size as x\n",
    "    #print(type(y[i]))\n",
    "    if df['class'][i].startswith('High-grade'):  # if the last column contains text \"High-grade\", etc below.\n",
    "        df['class'][i] = 'High-grade'\n",
    "    elif df['class'][i].startswith('Low-grade'):\n",
    "        df['class'][i] = 'Low-grade'\n",
    "    elif df['class'][i].startswith('Normal'):\n",
    "        df['class'][i] = 'Normal'\n",
    "# print (df.head())\n",
    "\n",
    "# Encode target variable (y)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoder = LabelEncoder()\n",
    "y= lbl_encoder.fit_transform(df['class'])\n",
    "# print(y) # shows how the classes are numerically assigned through this change, by 0,1, or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the indices of the words in the top percentage for correlation of IC: 1x300\n",
      "[43 44 45 46 48 49 50 51 52 53 54 55 56 57]\n",
      "This is the data accociated with each word: 148x300\n",
      "[[ 0.00923459 -0.00503947 -0.01090122 ...  0.03525511  0.03882811\n",
      "   0.0410134 ]\n",
      " [ 0.05830147  0.05247059  0.04463594 ...  0.04197936  0.04066504\n",
      "   0.03818964]\n",
      " [ 0.03734988  0.03838834  0.03837622 ...  0.02968341  0.03284243\n",
      "   0.03635363]\n",
      " ...\n",
      " [-0.17358487 -0.18647616 -0.19930839 ... -0.07645029 -0.08237044\n",
      "  -0.08957736]\n",
      " [-0.13591013 -0.17940675 -0.21859271 ... -0.15767263 -0.13891516\n",
      "  -0.10323525]\n",
      " [-0.08044461 -0.08512978 -0.08807086 ...  0.01298033  0.01124201\n",
      "   0.01155755]]\n",
      "top_x_percent_features.shape:  (324, 14)\n"
     ]
    }
   ],
   "source": [
    "# select only the top x% of features most correlated to the target variable. \n",
    "top_x_percent_features = SelectPercentile(f_regression, percentile=1).fit(x, y)\n",
    "indices = top_x_percent_features.get_support(True)\n",
    "print(\"These are the indices of the words in the top percentage for correlation of IC: 1x300\")\n",
    "print(indices)\n",
    "top_x_percent_features=top_x_percent_features.transform(x)\n",
    "print(\"This is the data accociated with each word: 148x300\")\n",
    "print(top_x_percent_features)\n",
    "print(\"top_x_percent_features.shape: \", top_x_percent_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_features will be the top 10% of words,which after mannually\n",
    "# filtering will be input into knime prediction algorithms. \n",
    "useful_feature_columns=[]\n",
    "for elem in indices: # elem = column name, str\n",
    "    useful_feature_columns.append(df.columns[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store useful words and features_new_percentile into a dataframe and export\n",
    "# it as a csv file named useful_words_unfiltered.csv\n",
    "i=0 # i represents the correct index from useful words and indices\n",
    "useful_features_df = pd.DataFrame()\n",
    "for elem in df: # elem represents the column name in df \n",
    "    if i < len(useful_feature_columns) and useful_feature_columns[i] == elem:\n",
    "        useful_features_df[elem] = df.iloc[:,indices[i]]\n",
    "        i+=1\n",
    "useful_features_df['class'] = df.iloc[:,1367]\n",
    "useful_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009235</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>-0.010901</td>\n",
       "      <td>-0.011113</td>\n",
       "      <td>-0.012657</td>\n",
       "      <td>-0.008263</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.022633</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.035255</td>\n",
       "      <td>0.038828</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>High-grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058301</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>0.044636</td>\n",
       "      <td>0.038812</td>\n",
       "      <td>0.031327</td>\n",
       "      <td>0.029738</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>0.031626</td>\n",
       "      <td>0.034681</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>0.041422</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>0.040665</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>High-grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037350</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>0.031165</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>0.029683</td>\n",
       "      <td>0.032842</td>\n",
       "      <td>0.036354</td>\n",
       "      <td>High-grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042067</td>\n",
       "      <td>0.042728</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>0.044145</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042016</td>\n",
       "      <td>0.041044</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.038802</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>0.036095</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>High-grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038427</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>0.047326</td>\n",
       "      <td>0.059380</td>\n",
       "      <td>0.069034</td>\n",
       "      <td>0.071380</td>\n",
       "      <td>0.068403</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.058752</td>\n",
       "      <td>0.057699</td>\n",
       "      <td>0.059073</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>High-grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>-0.029223</td>\n",
       "      <td>-0.047347</td>\n",
       "      <td>-0.060314</td>\n",
       "      <td>-0.063441</td>\n",
       "      <td>-0.033074</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.060637</td>\n",
       "      <td>0.069310</td>\n",
       "      <td>0.075353</td>\n",
       "      <td>0.078785</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.080989</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-0.070879</td>\n",
       "      <td>-0.051121</td>\n",
       "      <td>-0.024590</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.026772</td>\n",
       "      <td>0.023327</td>\n",
       "      <td>0.022308</td>\n",
       "      <td>0.022672</td>\n",
       "      <td>0.021214</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.028329</td>\n",
       "      <td>0.034440</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.173585</td>\n",
       "      <td>-0.186476</td>\n",
       "      <td>-0.199308</td>\n",
       "      <td>-0.202696</td>\n",
       "      <td>-0.157468</td>\n",
       "      <td>-0.123757</td>\n",
       "      <td>-0.093601</td>\n",
       "      <td>-0.075357</td>\n",
       "      <td>-0.068062</td>\n",
       "      <td>-0.067869</td>\n",
       "      <td>-0.071674</td>\n",
       "      <td>-0.076450</td>\n",
       "      <td>-0.082370</td>\n",
       "      <td>-0.089577</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>-0.135910</td>\n",
       "      <td>-0.179407</td>\n",
       "      <td>-0.218593</td>\n",
       "      <td>-0.221635</td>\n",
       "      <td>-0.051289</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>0.068650</td>\n",
       "      <td>0.045785</td>\n",
       "      <td>-0.017418</td>\n",
       "      <td>-0.088737</td>\n",
       "      <td>-0.143319</td>\n",
       "      <td>-0.157673</td>\n",
       "      <td>-0.138915</td>\n",
       "      <td>-0.103235</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>-0.080445</td>\n",
       "      <td>-0.085130</td>\n",
       "      <td>-0.088071</td>\n",
       "      <td>-0.089797</td>\n",
       "      <td>-0.093162</td>\n",
       "      <td>-0.087797</td>\n",
       "      <td>-0.078429</td>\n",
       "      <td>-0.074643</td>\n",
       "      <td>-0.065997</td>\n",
       "      <td>-0.034378</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           44        45        46        47        49        50        51  \\\n",
       "0    0.009235 -0.005039 -0.010901 -0.011113 -0.012657 -0.008263 -0.001059   \n",
       "1    0.058301  0.052471  0.044636  0.038812  0.031327  0.029738  0.029778   \n",
       "2    0.037350  0.038388  0.038376  0.037082  0.031165  0.027429  0.024327   \n",
       "3    0.042067  0.042728  0.043539  0.044145  0.043726  0.042965  0.042016   \n",
       "4    0.038427  0.030893  0.028235  0.030835  0.047326  0.059380  0.069034   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "319 -0.029223 -0.047347 -0.060314 -0.063441 -0.033074 -0.001810  0.030006   \n",
       "320 -0.070879 -0.051121 -0.024590  0.001054  0.026383  0.026772  0.023327   \n",
       "321 -0.173585 -0.186476 -0.199308 -0.202696 -0.157468 -0.123757 -0.093601   \n",
       "322 -0.135910 -0.179407 -0.218593 -0.221635 -0.051289  0.030249  0.068650   \n",
       "323 -0.080445 -0.085130 -0.088071 -0.089797 -0.093162 -0.087797 -0.078429   \n",
       "\n",
       "           52        53        54        55        56        57        58  \\\n",
       "0    0.006600  0.014492  0.022633  0.029907  0.035255  0.038828  0.041013   \n",
       "1    0.031626  0.034681  0.038481  0.041422  0.041979  0.040665  0.038190   \n",
       "2    0.022960  0.023200  0.024617  0.026905  0.029683  0.032842  0.036354   \n",
       "3    0.041044  0.040001  0.038802  0.037506  0.036095  0.034710  0.033477   \n",
       "4    0.071380  0.068403  0.063301  0.058752  0.057699  0.059073  0.060811   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "319  0.049800  0.060637  0.069310  0.075353  0.078785  0.080648  0.080989   \n",
       "320  0.022308  0.022672  0.021214  0.020468  0.023199  0.028329  0.034440   \n",
       "321 -0.075357 -0.068062 -0.067869 -0.071674 -0.076450 -0.082370 -0.089577   \n",
       "322  0.045785 -0.017418 -0.088737 -0.143319 -0.157673 -0.138915 -0.103235   \n",
       "323 -0.074643 -0.065997 -0.034378  0.001017  0.012980  0.011242  0.011558   \n",
       "\n",
       "          class  \n",
       "0    High-grade  \n",
       "1    High-grade  \n",
       "2    High-grade  \n",
       "3    High-grade  \n",
       "4    High-grade  \n",
       "..          ...  \n",
       "319      Normal  \n",
       "320      Normal  \n",
       "321      Normal  \n",
       "322      Normal  \n",
       "323      Normal  \n",
       "\n",
       "[324 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features_df.to_csv(r'C:\\Users\\R-k-l\\AppData\\Local\\Programs\\Python\\Python37\\Scripts\\Capstone\\useful_features_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
