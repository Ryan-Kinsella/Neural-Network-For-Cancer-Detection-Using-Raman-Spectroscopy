{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow_core._api.v2.version' from 'c:\\\\users\\\\r-k-l\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\tensorflow_core\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.svm import SVC\n",
    "print(tf.version) # tensorflow 2.0\n",
    "pd.options.display.max_rows = 8 # will use 8 by default for count, mean, std ... max\n",
    "pd.options.display.max_columns = 9\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"useful_features_50.csv\")\n",
    "\n",
    "# change y in the csv file to be assigned to one of three classes: High-grade, Low-grade, Normal\n",
    "for i in range (0,324): # 0 - 323, same size as x\n",
    "    #print(type(y[i]))\n",
    "    if df['class'][i].startswith('High-grade'):  # if the last column contains text \"High-grade\", etc below.\n",
    "        df['class'][i] = 'High-grade'\n",
    "    elif df['class'][i].startswith('Low-grade'):\n",
    "        df['class'][i] = 'Low-grade'\n",
    "    elif df['class'][i].startswith('Normal'):\n",
    "        df['class'][i] = 'Normal'\n",
    "# GIVES WARNINGS although it still works, see print below\n",
    "# print (df.head())\n",
    "\n",
    "# https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test\n",
    "# x represents attributes, y represents class label\n",
    "training, validation, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) # 60% test, 20% validation, 20% test split.\n",
    "x_train = training.drop(['class'], axis=1)\n",
    "y_train = training['class']\n",
    "x_validation=validation.drop(['class'], axis=1)\n",
    "y_validation=validation['class']\n",
    "x_test=test.drop(['class'], axis=1)\n",
    "y_test=test['class']\n",
    "# Encode class label y to be 0, 1, or 2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoder = LabelEncoder()\n",
    "y_train= lbl_encoder.fit_transform(y_train)\n",
    "y_test= lbl_encoder.fit_transform(y_test)\n",
    "y_validation= lbl_encoder.fit_transform(y_validation)\n",
    "del training, validation, test # clear memory of variables not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def construct_feature_columns(input_features_DataFrame):\n",
    "#   \"\"\"Construct the TensorFlow Feature Columns.\n",
    "#   Args:\n",
    "#     input_features: DataFrame with the names of the numerical input features to use.\n",
    "#   Returns:\n",
    "#     A set of tf numeric feature columns\n",
    "#   \"\"\"\n",
    "#   tensorSet = ([])\n",
    "#   for elem in input_features_DataFrame:\n",
    "#     tensorSet.append(tf.feature_column.numeric_column(key=str(elem), dtype=tf.dtypes.float64) ) # where elem is a str feature label\n",
    "#   return tensorSet\n",
    "\n",
    "# # Create the input function for training + evaluation. boolean = True for training.\n",
    "# def input_fn(features, labels, training=True, batch_size=32 ):\n",
    "#     dataf = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "#     if training:\n",
    "#         dataf = dataf.shuffle(100).repeat() # shuffle ~<half the data\n",
    "#     return dataf.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construct feature columns, which is a list of tensors with the feature names, shown below. \n",
    "# feature_columns=construct_feature_columns(df.drop(['class'], axis=1).head(0))\n",
    "# len(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.estimator.BoostedTreesClassifier(feature_columns, n_batches_per_layer = 1,  n_classes=3, pruning_mode=None)\n",
    "# model.train(input_fn=lambda: input_fn(features=x_train, labels=y_train, training=True), max_steps=1000)\n",
    "# validation_results = model.evaluate(input_fn=lambda: input_fn(features=x_validation, labels=y_validation, training=False), steps=1)\n",
    "# testing_results = model.evaluate(input_fn=lambda: input_fn(features=x_test, labels=y_test, training=False), steps=1)\n",
    "# print(\"Validation results: \")\n",
    "# print(validation_results)\n",
    "# print(\"Testing results: \")\n",
    "# print(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 2, 1, 0, 1, 0, 0, 0, 1, 2, 1, 0, 0, 0, 1, 1, 2, 2, 1, 0, 1, 0,\n",
       "       1, 0, 2, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "svclassifier = SVC(kernel='linear', probability=True)\n",
    "svclassifier.fit(x_train, y_train)\n",
    "\n",
    "#predict\n",
    "svm_predictions = svclassifier.predict(x_test)\n",
    "svclassifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615384615384616"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.score(x_test, y_test) # returns accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(svclassifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  1]\n",
      " [ 0 19  2]\n",
      " [ 5  1  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.86      0.97      0.91        31\n",
      "      Medium       0.95      0.90      0.93        21\n",
      "         Low       0.70      0.54      0.61        13\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.84      0.80      0.81        65\n",
      "weighted avg       0.86      0.86      0.85        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, target_names=[\"High\", \"Medium\", \"Low\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
